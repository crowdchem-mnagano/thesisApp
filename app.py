import streamlit as st
import pandas as pd
import json
import os
import shutil
import re
from copy import deepcopy
from io import BytesIO
import zipfile

# ==========================================
# Streamlit UI
# ==========================================
st.set_page_config(page_title="Excelâ†’JSON tool", layout="wide")
st.title("Excel â†’ JSON tool / Excel â†’ JSON ãƒ„ãƒ¼ãƒ«")

st.markdown("""
### ğŸ“˜ ã“ã®ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½ / About this tool
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼š  
This app performs the following steps:

1. **JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**  
   Upload the JSON template file.  
2. **Excelãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆå›ºå®šæ§‹é€ ï¼‰**  
   - 1è¡Œç›®: ã‚«ãƒ†ã‚´ãƒª  
   - 2è¡Œç›®: æ­£å¼å  
   - 3è¡Œç›®: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ (%A1%, %B1%, â€¦)  
   - 4è¡Œç›®: ç•¥ç§°ï¼ˆä»»æ„ï¼‰  
   - 5è¡Œç›®ä»¥é™: ãƒ‡ãƒ¼ã‚¿ï¼ˆæ•°å€¤ã‚„æ–‡å­—åˆ—ï¼‰  
3. **ç½®æ›å®Ÿè¡Œæ™‚ã®å‹•ä½œ**  
   | çŠ¶æ³ | å‹•ä½œ |
   |------|------|
   | Excel ã«åŒã˜ã‚­ãƒ¼ãŒã‚ã‚‹ | æ­£å¸¸ç½®æ› |
   | Excel ã«ã‚­ãƒ¼ãŒãªã„ | ğŸ”¶ warning ã«å‡ºã™ |
   | Excel ã«ã‚­ãƒ¼ãŒã‚ã£ã¦å€¤ãŒç©º/NaN/"0"/"none" | âš ï¸ `{}` ã”ã¨å‰Šé™¤ |
   | JSON å†…ã« `%â€¦%` ãŒæ®‹ã£ãŸ | ğŸ”´ errorï¼ˆ%xx%ãŒç½®æ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰ |
""")

# ==========================================
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ==========================================
json_file = st.file_uploader("ğŸ“„ JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["json"])
excel_file = st.file_uploader("ğŸ“Š Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx", "xls"])

output_dir = "output_json"
if os.path.exists(output_dir):
    shutil.rmtree(output_dir)
os.makedirs(output_dir, exist_ok=True)

# ==========================================
# Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
# ==========================================
def validate_excel(raw):
    errors = []
    if len(raw) < 5:
        errors.append("âŒ è¡Œæ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½5è¡Œå¿…è¦ï¼‰ / Not enough rows (minimum 5 required).")
    if len(raw) >= 3:
        placeholder_row = raw.iloc[2].tolist()
        invalid = [f"åˆ—{idx+1}" for idx, val in enumerate(placeholder_row)
                   if not re.match(r"^%[A-Za-z0-9_]+%$", str(val).strip())]
        if invalid:
            errors.append(f"âŒ 3è¡Œç›®ã®{', '.join(invalid)} ã«ä¸æ­£ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã™ / Invalid placeholders in row 3: {', '.join(invalid)}.")
    if len(raw) >= 3 and len(raw.iloc[1]) != len(raw.iloc[2]):
        errors.append("âŒ 2è¡Œç›®ã¨3è¡Œç›®ã®åˆ—æ•°ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ / Row 2 and row 3 column counts differ.")
    if errors:
        return False, "\n".join(errors)
    return True, "âœ… Excelæ§‹é€ ã¯æ­£å¸¸ã§ã™ / Excel structure validated successfully."

# ==========================================
# conditions / properties / materials ã®å…±é€šç½®æ›å‡¦ç†
# ==========================================
def replace_and_clean(obj_list, row, unmatched_keys):
    """conditions / properties / materials[*].properties ã«å¯¾å¿œã€‚ç©ºå€¤ãªã‚‰ {} ã”ã¨å‰Šé™¤ã€‚"""
    if not isinstance(obj_list, list):
        return []
    new_list = []
    for obj in obj_list:
        v = obj.get("value")
        if isinstance(v, str):
            if v in row:  # Excelã«åŒã˜ã‚­ãƒ¼ãŒã‚ã‚‹
                val = row[v]
                if pd.isna(val) or str(val).strip().lower() in ["", "none", "0", "0.0"]:
                    # ç©ºå€¤ã¯å‰Šé™¤å¯¾è±¡
                    continue
                else:
                    obj["value"] = str(val)
                    new_list.append(obj)
            else:
                unmatched_keys.add(v)  # Excelã«ã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„
        else:
            new_list.append(obj)
    return new_list

# ==========================================
# å®Ÿè¡Œãƒœã‚¿ãƒ³
# ==========================================
if st.button("ğŸš€ å¤‰æ›ã‚’å®Ÿè¡Œ / Run conversion", type="primary"):
    if json_file is None or excel_file is None:
        st.error("âš  JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¡æ–¹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ / Please upload both JSON and Excel files.")
    else:
        try:
            # === JSONèª­ã¿è¾¼ã¿ ===
            json_template = json.load(json_file)
            json_filename = os.path.splitext(os.path.basename(json_file.name))[0]

            # === Excelèª­ã¿è¾¼ã¿ ===
            raw = pd.read_excel(excel_file, header=None, dtype=str).fillna("")

            ok, msg = validate_excel(raw)
            if not ok:
                st.error(msg)
                st.stop()
            else:
                st.success(msg)

            # === Excelãƒ‡ãƒ¼ã‚¿æº–å‚™ ===
            labels = [str(x).strip() for x in raw.iloc[2]]  # 3è¡Œç›®ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€è¡Œï¼‰ã‚’æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿
            # ğŸ”§ ã“ã“ã§è‡ªå‹•çš„ã« %...% å½¢å¼ã«è£œæ­£ï¼ˆä¾‹: "A1" â†’ "%A1%"ï¼‰
            labels = [("%" + x.strip("%") + "%") if not str(x).startswith("%") else str(x) for x in labels]

            data = raw.iloc[4:].reset_index(drop=True)
            data.columns = labels

            st.info(f"Excelã« {len(data)} è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ / Found {len(data)} data rows.")

            progress_bar = st.progress(0)
            status_text = st.empty()
            generated_files = []
            unmatched_keys_global = set()

            # === è¡Œå˜ä½å‡¦ç† ===
            for idx, row in data.iterrows():
                d = deepcopy(json_template)
                unmatched_keys = set()

                # --- processes å†… conditions/properties ---
                for proc in d["examples"][0]["processes"]:
                    proc["conditions"] = replace_and_clean(proc.get("conditions", []), row, unmatched_keys)
                    proc["properties"] = replace_and_clean(proc.get("properties", []), row, unmatched_keys)

                # --- materials å†… properties ---
                for mat in d.get("materials", []):
                    mat["properties"] = replace_and_clean(mat.get("properties", []), row, unmatched_keys)

                # --- æœªä¸€è‡´ã‚­ãƒ¼åé›† ---
                if unmatched_keys:
                    unmatched_keys_global |= unmatched_keys
                    st.warning(f"âš  æœªä¸€è‡´ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼ˆè¡Œ {idx+1}ï¼‰: {', '.join(sorted(unmatched_keys))}")

                # --- æœªç½®æ›ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€æ¤œå‡º ---
                j_str = json.dumps(d, ensure_ascii=False)
                leftovers = re.findall(r"%[A-Za-z0-9_]+%", j_str)
                if leftovers:
                    st.error(f"âŒ æœªç½®æ›ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã™ï¼ˆè¡Œ {idx+1}ï¼‰: {', '.join(sorted(set(leftovers)))}")
                    st.stop()

                d = json.loads(j_str)

                # --- ä¿å­˜ ---
                output_path = os.path.join(output_dir, f"{json_filename}_{idx}.json")
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(d, f, ensure_ascii=False, indent=2)
                generated_files.append(output_path)

                progress_bar.progress((idx + 1) / len(data))
                status_text.text(f"{idx+1}/{len(data)} ä»¶å‡¦ç†å®Œäº† / {idx+1}/{len(data)} rows processed")

            # === ZIPåŒ– ===
            zip_buffer = BytesIO()
            with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
                for file in generated_files:
                    zipf.write(file, os.path.basename(file))
            zip_buffer.seek(0)

            # === çµ‚äº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ===
            if unmatched_keys_global:
                st.warning(f"âš  ä»¥ä¸‹ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã¯Excelã«å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸ: {', '.join(sorted(unmatched_keys_global))}")

            st.success("âœ… å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼ / âœ… Conversion completed successfully!")
            st.download_button(
                "å‡ºåŠ›çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP) / Download results (ZIP)",
                data=zip_buffer,
                file_name=f"{json_filename}_output.zip",
                mime="application/zip"
            )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e} / An error occurred: {e}")
