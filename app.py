import streamlit as st
import pandas as pd
import json
import os
import shutil
import re
from copy import deepcopy
from io import BytesIO
import zipfile

# ==========================================
# Streamlit UI éƒ¨åˆ† / Streamlit UI section
# ==========================================
st.set_page_config(page_title="Excelâ†’JSON tool", layout="wide")
st.title("Excel â†’ JSON tool / Excel â†’ JSON ãƒ„ãƒ¼ãƒ«")

st.markdown("""
### ğŸ“˜ ã“ã®ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½ / About this tool
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼š  
This app performs the following steps:

1. **JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**  
   Upload the JSON template file.  

2. **Excelãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**  
   Excelå½¢å¼ã¯å¿…ãšä»¥ä¸‹ã®æ§‹æˆã§çµ±ä¸€ã—ã¦ãã ã•ã„ï¼š  
   Please ensure your Excel follows this fixed format:  
   - 1è¡Œç›® / Row 1 â†’ ææ–™ã‚«ãƒ†ã‚´ãƒª (Category: Resin, Hardener, etc.)  
   - 2è¡Œç›® / Row 2 â†’ æ­£å¼å (Formal name: IUPAC or trade name)  
   - 3è¡Œç›® / Row 3 â†’ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ (%A1%, %B1%, â€¦)  
   - 4è¡Œç›® / Row 4 â†’ ç•¥ç§° (Abbreviation: short labels used in data rows)  
   - 5è¡Œç›®ä»¥é™ / Row 5 onward â†’ ãƒ‡ãƒ¼ã‚¿ (Numeric or text data)

3. **å„è¡Œã”ã¨ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç½®æ›**  
   Replace placeholders in the JSON template row by row  
   (apply material deletion and property replacement rules).  

4. **ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸJSONåãƒ™ãƒ¼ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›**  
   Output JSON files named based on the uploaded template.  

5. **ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½**  
   Download all converted JSON files as a ZIP archive.  

---

âš ï¸ **æ³¨æ„ / Notes**  
- Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç•°ãªã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ã¾ã™ã€‚  
  If your Excel structure does not follow the required format, processing will stop with an error message.  
- å„ã‚»ãƒ«ã®ç©ºæ¬„ãƒ»0ãƒ»"none" ã¯è‡ªå‹•çš„ã«å‰Šé™¤ã•ã‚Œã¾ã™ã€‚  
  Blank cells, "0", or "none" are automatically excluded.  
- Excelã¯UTF-8äº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä¿å­˜ã—ã¦ãã ã•ã„ã€‚  
  Save Excel files in UTF-8 compatible format (no special characters).  

""")

# ==========================================
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ / File upload
# ==========================================
json_file = st.file_uploader("ğŸ“„ JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ / Upload JSON template", type=["json"])
excel_file = st.file_uploader("ğŸ“Š Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ / Upload Excel file", type=["xlsx", "xls"])

output_dir = "output_json"
if os.path.exists(output_dir):
    shutil.rmtree(output_dir)
os.makedirs(output_dir, exist_ok=True)


# ==========================================
# Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼é–¢æ•° / Excel validation
# ==========================================
def validate_excel(raw):
    """
    Excelæ§‹é€ ã¨å†…å®¹ã‚’æ¤œè¨¼ã™ã‚‹ / Validate Excel structure and content.
    å•é¡ŒãŒã‚ã‚Œã° (False, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ–‡å­—åˆ—) ã‚’è¿”ã™ã€‚
    Return (False, message) if any issues are found.
    """
    errors = []

    # --- è¡Œæ•°ãƒã‚§ãƒƒã‚¯ / Row count check ---
    if len(raw) < 5:
        errors.append("âŒ è¡Œæ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½5è¡Œå¿…è¦ï¼šã‚«ãƒ†ã‚´ãƒªãƒ»æ­£å¼åãƒ»%è¨˜å·ãƒ»ç•¥ç§°ãƒ»ãƒ‡ãƒ¼ã‚¿ï¼‰ / Not enough rows. Minimum 5 required: category, formal, placeholder, abbreviation, data.")

    # --- ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€è¡Œ(%XX%)ã®æ¤œè¨¼ / Placeholder format check ---
    if len(raw) >= 3:
        placeholder_row = raw.iloc[2].tolist()
        invalid = [f"åˆ—{idx+1}" for idx, val in enumerate(placeholder_row)
                   if not str(val).startswith("%") or not str(val).endswith("%")]
        if invalid:
            errors.append(f"âŒ 3è¡Œç›®ã®{', '.join(invalid)} ã«ä¸æ­£ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã™ï¼ˆ'%A1%' ã®ã‚ˆã†ãªå½¢å¼ãŒå¿…è¦ï¼‰ / Invalid placeholders found in row 3 ({', '.join(invalid)}). They must follow the format like '%A1%'. ")

    # --- ç•¥ç§°è¡Œã®ç©ºæ¬„ãƒã‚§ãƒƒã‚¯ / Abbreviation check ---
    if len(raw) >= 4:
        abbr_row = raw.iloc[3].tolist()
        empty_abbr = [f"åˆ—{idx+1}" for idx, val in enumerate(abbr_row)
                      if str(val).strip() == "" or str(val).lower() == "nan"]
        if empty_abbr:
            errors.append(f"âš ï¸ 4è¡Œç›®ã®{', '.join(empty_abbr)} ãŒç©ºæ¬„ã§ã™ï¼ˆç•¥ç§°ãŒå¿…è¦ï¼‰ / Empty abbreviations found in row 4 ({', '.join(empty_abbr)}). Each column needs an abbreviation label.")

    # --- æ­£å¼åè¡Œã¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€è¡Œã®åˆ—æ•°ä¸€è‡´ / Column count consistency ---
    if len(raw) >= 3 and len(raw.iloc[1]) != len(raw.iloc[2]):
        errors.append("âŒ 2è¡Œç›®ï¼ˆæ­£å¼åï¼‰ã¨3è¡Œç›®ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰ã®åˆ—æ•°ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ / The number of columns in row 2 (formal names) and row 3 (placeholders) do not match.")

    # --- ãƒ‡ãƒ¼ã‚¿è¡Œï¼ˆ5è¡Œç›®ä»¥é™ï¼‰ã®ç©ºè¡Œãƒã‚§ãƒƒã‚¯ / Empty data rows ---
    if len(raw) >= 5:
        data = raw.iloc[4:].fillna("")
        for r_idx, row in data.iterrows():
            if all(str(x).strip() == "" for x in row):
                errors.append(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®è¡ŒãŒã‚ã‚Šã¾ã™ï¼ˆExcel {r_idx + 5} è¡Œç›®ï¼‰ / Empty data row detected (Excel row {r_idx + 5}).")

    if errors:
        return False, "\n".join(errors)
    else:
        return True, "âœ… Excelæ§‹é€ ã¯æ­£å¸¸ã§ã™ / Excel structure validated successfully."


# ==========================================
# ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ç½®æ›é–¢æ•° / Property replacement function
# ==========================================
def fill_properties(props, row, mapping):
    """ç‰©æ€§: 0ã¯æ®‹ã™ / ç©ºæ¬„(None, '', 'none')ã¯ç©ºæ–‡å­—ã«"""
    if not isinstance(props, list):
        return
    for prop in props:
        v = prop.get("value")
        if isinstance(v, str) and v in mapping:
            col = mapping[v]
            val = row[col] if col in row else None
            if pd.isna(val) or str(val).strip().lower() in ["", "none"]:
                prop["value"] = ""
            else:
                prop["value"] = str(val)


# ==========================================
# å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³ / Execute process button
# ==========================================
if st.button("ğŸš€ å¤‰æ›ã‚’å®Ÿè¡Œ / Run conversion", type="primary"):
    if json_file is None or excel_file is None:
        st.error("âš  JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¡æ–¹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ / Please upload both JSON and Excel files.")
    else:
        try:
            # JSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ / Load JSON template
            json_template = json.load(json_file)
            json_filename = os.path.splitext(os.path.basename(json_file.name))[0]

            # Excelèª­ã¿è¾¼ã¿ / Read Excel
            raw = pd.read_excel(excel_file, header=None, dtype=str)
            raw = raw.fillna("")

            # === æ§‹é€ æ¤œè¨¼ / Validate structure ===
            ok, msg = validate_excel(raw)
            if not ok:
                st.error("Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™ / Excel format issues detected:")
                st.error(msg)
                st.stop()
            else:
                st.success(msg)

            # === ãƒ‡ãƒ¼ã‚¿æŠ½å‡º / Extract data ===
            formals = [str(x).strip() for x in raw.iloc[1]]  # æ­£å¼å / Formal names
            labels = [str(x).strip() for x in raw.iloc[2]]   # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ / Placeholders
            abbrs  = [str(x).strip() for x in raw.iloc[3]]   # ç•¥ç§° / Abbreviations
            data   = raw.iloc[4:].reset_index(drop=True)     # ãƒ‡ãƒ¼ã‚¿æœ¬ä½“ / Main data
            data.columns = abbrs

            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€â†’ç•¥ç§°å¯¾å¿œè¡¨ / Mapping: placeholder â†’ abbreviation
            mapping = {lab: abbr for lab, abbr in zip(labels, abbrs) if lab and abbr}

            st.info(f"Excelã« {len(data)} è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ / Found {len(data)} rows of data in Excel.")

            # === å„è¡Œã”ã¨ã®å‡¦ç† / Process each row ===
            progress_bar = st.progress(0)
            status_text = st.empty()
            generated_files = []

            for idx, row in data.iterrows():
                d = deepcopy(json_template)

                # --- materialsï¼ˆæœ€åˆã®processï¼‰ / First process materials ---
                new_materials = []
                for m in d["examples"][0]["processes"][0]["materials"]:
                    amount = m.get("amount")
                    if isinstance(amount, str) and amount in mapping:
                        col = mapping[amount]
                        val = row[col] if col in row else ""
                        v = str(val).strip()
                        if v in ["", "none", "0", "0.0"]:
                            continue  # æœªå…¥åŠ›ãƒ»0ã¯å‰Šé™¤ / Skip empty or zero values
                        m["amount"] = v
                    else:
                        if not amount or (isinstance(amount, str) and amount.startswith("%")):
                            continue
                    new_materials.append(m)
                d["examples"][0]["processes"][0]["materials"] = new_materials

                # --- propertiesï¼ˆãƒ—ãƒ­ã‚»ã‚¹å†…ï¼‰ / Properties inside process ---
                for proc in d["examples"][0]["processes"]:
                    fill_properties(proc.get("properties", []), row, mapping)
                # --- ãƒ«ãƒ¼ãƒˆç›´ä¸‹ materials[*].properties ã‚‚ç½®æ› / Root-level materials properties ---
                for mat in d.get("materials", []):
                    fill_properties(mat.get("properties", []), row, mapping)

                # --- æœªç½®æ›ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€å‰Šé™¤ / Remove unreplaced placeholders ---
                j_str = json.dumps(d, ensure_ascii=False)
                j_str = re.sub(r"%[A-Za-z0-9]+%", "", j_str)
                d = json.loads(j_str)

                # --- ä¿å­˜ / Save file ---
                output_path = os.path.join(output_dir, f"{json_filename}_{idx}.json")
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(d, f, ensure_ascii=False, indent=2)
                generated_files.append(output_path)

                progress_bar.progress((idx + 1) / len(data))
                status_text.text(f"{idx+1}/{len(data)} ä»¶å‡¦ç†å®Œäº† / {idx+1}/{len(data)} rows processed")

            # ZIPåŒ–ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ / Zip and download
            zip_buffer = BytesIO()
            with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
                for file in generated_files:
                    zipf.write(file, os.path.basename(file))
            zip_buffer.seek(0)

            st.success("âœ… å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼ / âœ… Conversion completed successfully!")
            st.download_button(
                "å‡ºåŠ›çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP) / Download results (ZIP)",
                data=zip_buffer,
                file_name=f"{json_filename}_output.zip",
                mime="application/zip"
            )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e} / An error occurred: {e}")
